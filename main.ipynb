{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afaf0ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, Lambda\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0294dbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NUM = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1655c1c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def mnist_loader(train: bool, batch_size: int) -> DataLoader:\n",
    "    '''\n",
    "    pytorch MNIST train & test 데이터 로더 반환\n",
    "    + z-normalization\n",
    "    + Flatten\n",
    "    '''\n",
    "    transform = Compose([\n",
    "        ToTensor(),\n",
    "        Normalize(mean=(0.1307, ), std=(0.3081, )),\n",
    "        Lambda(lambda x: torch.flatten(x)),\n",
    "    ])\n",
    "\n",
    "    loader = DataLoader(\n",
    "        MNIST(\n",
    "            root='./mnist/',\n",
    "            train=train,\n",
    "            transform=transform,\n",
    "            download=True\n",
    "        ), shuffle=train, batch_size=batch_size\n",
    "    )\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "551cad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_xy(x: Tensor, y: Tensor) -> Tensor:\n",
    "    '''\n",
    "    forward-forward Model 입력 데이터 반환\n",
    "\n",
    "    X shape: Batch x 784(Ch * Height * Width)\n",
    "    Y shape: Batch x Label\n",
    "    '''\n",
    "    batch_size = y.size(0)\n",
    "\n",
    "    x_ = x.clone()\n",
    "    x_[:, :CLASS_NUM] = 0.\n",
    "    x_[range(batch_size), y] = x_.max()\n",
    "    return x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80796f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFLinear(nn.Linear):\n",
    "    __constants__ = ('in_features', 'out_features')\n",
    "    in_features: int\n",
    "    out_features: int\n",
    "    weight: Tensor\n",
    "        \n",
    "    def __init__(self, in_feature: int, out_features: int, bias: bool=True, device=None, dtype=None) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super(FFLinear, self).__init__(in_feature, out_features, bias, **factory_kwargs)\n",
    "        \n",
    "        self.activation = nn.ReLU()\n",
    "        self.optim = torch.optim.SGD(self.parameters(), lr=0.1)\n",
    "        self.threshold = 2.0\n",
    "        \n",
    "    def forward(self, input) -> Tensor:\n",
    "        out = self.__layerNorm(input)\n",
    "        out = F.linear(out, self.weight, self.bias)\n",
    "        return self.activation(out)\n",
    "    \n",
    "    def update(self, pos_x, neg_x) -> (Tensor, (Tensor, Tensor)):\n",
    "        pos_out = self.forward(pos_x).pow(exponent=2).mean(dim=1) #shape: (Batch, )\n",
    "        neg_out = self.forward(neg_x).pow(exponent=2).mean(dim=1) #shape: (Batch, )\n",
    "        \n",
    "        loss = torch.cat([-pos_out + self.threshold, neg_out - self.threshold])\n",
    "        loss = torch.log(1. + torch.exp(loss)).mean()\n",
    "        \n",
    "        self.optim.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "        return (self.forward(pos_x).detach(), self.forward(neg_x).detach())\n",
    "    \n",
    "    def __layerNorm(self, input: Tensor, eps: float=1e-4) -> Tensor:\n",
    "        '''\n",
    "        + 참고 repository의 정규화 코드\n",
    "        input / (input.norm(p=2, dim=1, keepdim=True) + 1e-4)\n",
    "        \n",
    "        ## https://github.com/mohammadpz/pytorch_forward_forward/blob/main/main.py\n",
    "        '''\n",
    "        mean_ = input.mean(dim=1, keepdim=True)\n",
    "        var_ = input.var(dim=1, keepdim=True, unbiased=False) #unbiased True=(N-1), False=N\n",
    "        return (input - mean_) / torch.sqrt(var_ + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "677b2c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFModel(nn.Module):\n",
    "    __constants__ = ('dims', )\n",
    "    dims: list\n",
    "        \n",
    "    def __init__(self, dims: list, device='cpu') -> None:\n",
    "        super(FFModel, self).__init__()\n",
    "        self.layers = tuple(FFLinear(dims[d], dims[d+1]).to(device) for d in range(len(dims) - 1))\n",
    "\n",
    "    def forward(self, input) -> Tensor:\n",
    "        batch_size = input.size(0)\n",
    "        goodness = torch.zeros(batch_size)\n",
    "\n",
    "        out = input\n",
    "        for layer in self.layers:\n",
    "            out = layer(out)\n",
    "            goodness += out.pow(exponent=2).mean(dim=1)\n",
    "        return goodness\n",
    "    \n",
    "    def update(self, pos_x: Tensor, neg_x: Tensor) -> None:\n",
    "        pos_out, neg_out = pos_x, neg_x\n",
    "        for layer in self.layers:\n",
    "            pos_out, neg_out = layer.update(pos_out, neg_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f70f12b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neg_y(y: Tensor, class_num: int) -> Tensor:\n",
    "    batch_size = y.size(0)\n",
    "    \n",
    "    able_idxs = torch.arange(class_num).unsqueeze(0).repeat(batch_size, 1)\n",
    "    able_idxs = able_idxs[able_idxs != y.view(batch_size, 1)].view(batch_size, class_num-1)\n",
    "    \n",
    "    rand_idxs = torch.randint(class_num - 1, size=(batch_size, ))\n",
    "    return able_idxs[range(batch_size), rand_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1f8cd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:09<00:00, 536.03it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:09<00:00, 540.16it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:09<00:00, 548.22it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:09<00:00, 548.41it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:09<00:00, 555.32it/s]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1\n",
    "EPOCHS = 5\n",
    "\n",
    "\n",
    "model = FFModel(dims=(784, 100, 100))\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "    train_loader = iter(mnist_loader(train=False, batch_size=BATCH_SIZE))\n",
    "    for (pos_x, pos_y), (neg_x, neg_y) in tqdm(zip(train_loader, train_loader), total=5000):\n",
    "        pos_x = combine_xy(pos_x, pos_y)\n",
    "\n",
    "        neg_y = get_neg_y(neg_y, class_num=CLASS_NUM)\n",
    "        neg_x = combine_xy(neg_x, neg_y)\n",
    "\n",
    "        model.update(pos_x, neg_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3af25b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 235/235 [00:09<00:00, 24.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8557833333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loader = mnist_loader(train=True, batch_size=256)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    acc = list()\n",
    "    for x, y in tqdm(train_loader):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        x = x.unsqueeze(1).repeat(1, CLASS_NUM, 1).view(-1, 784)\n",
    "        y_batchs = torch.arange(CLASS_NUM).repeat(batch_size)\n",
    "        x = combine_xy(x, y_batchs)\n",
    "\n",
    "        goodness = model(x).view(batch_size, -1)\n",
    "\n",
    "        y_hat = goodness.argmax(dim=1)\n",
    "        acc.extend(y_hat.eq(y).float().tolist())\n",
    "        \n",
    "        \n",
    "print(sum(acc) / len(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60345b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 25.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loader = mnist_loader(train=False, batch_size=256)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    acc = list()\n",
    "    for x, y in tqdm(test_loader):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        x = x.unsqueeze(1).repeat(1, CLASS_NUM, 1).view(-1, 784)\n",
    "        y_batchs = torch.arange(CLASS_NUM).repeat(batch_size)\n",
    "        x = combine_xy(x, y_batchs)\n",
    "\n",
    "        goodness = model(x).view(batch_size, -1)\n",
    "\n",
    "        y_hat = goodness.argmax(dim=1)\n",
    "        acc.extend(y_hat.eq(y).float().tolist())\n",
    "        \n",
    "        \n",
    "print(sum(acc) / len(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d20f15a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
