{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afaf0ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, Lambda\n",
    "\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a2470bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loader(train_batch_size: int=1, test_batch_size: int=1) -> (DataLoader, DataLoader):\n",
    "    '''\n",
    "    pytorch MNIST train & test 데이터 로더 반환\n",
    "    + z-normalization\n",
    "    + Flatten\n",
    "    '''\n",
    "    transform = Compose([\n",
    "        ToTensor(),\n",
    "        Normalize(mean=(0.1307, ), std=(0.3081, )),\n",
    "        Lambda(lambda x: torch.flatten(x)),\n",
    "    ])\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        MNIST(\n",
    "            root='./mnist/',\n",
    "            train=True,\n",
    "            transform=transform,\n",
    "            download=True\n",
    "        ), shuffle=True, batch_size=train_batch_size\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        MNIST(\n",
    "            root='./mnist/',\n",
    "            train=False,\n",
    "            transform=transform,\n",
    "            download=True\n",
    "        ), shuffle=False, batch_size=test_batch_size\n",
    "    )\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66c0ff6a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_input_data(x: Tensor, y: Tensor) -> Tensor:\n",
    "    '''\n",
    "    forward-forward Model 입력 데이터 반환\n",
    "    \n",
    "    X shape: Batch x 784(Ch * Height * Width)\n",
    "    Y shape: Batch x Label\n",
    "    '''\n",
    "    batch_size = y.size(0)\n",
    "    \n",
    "    x_ = x.clone()\n",
    "    x_[:, :10] = 0.\n",
    "    x_[range(batch_size), y] = x_.max()\n",
    "    return x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80796f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3620,  0.6799,  0.2078, -1.0088],\n",
      "        [-0.0130,  1.0682, -1.3792, -1.3598]])\n",
      "tensor([[-0.2595,  0.4917,  1.3721, -1.1487],\n",
      "        [ 0.3802, -1.0547,  2.2308, -0.9562]])\n",
      "==================================================\n",
      "tensor([0.5960, 0.4617], grad_fn=<MeanBackward1>)\n",
      "tensor([0.7995, 0.9600], grad_fn=<MeanBackward1>)\n",
      "==================================================\n",
      "tensor([1.4040, 1.5383], grad_fn=<AddBackward0>)\n",
      "tensor([-1.2005, -1.0400], grad_fn=<SubBackward0>)\n",
      "==================================================\n",
      "tensor([5.0716, 5.6568, 1.3010, 1.3535], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 62\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(pos_x)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(neg_x)\n\u001b[1;32m---> 62\u001b[0m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg_x\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[23], line 39\u001b[0m, in \u001b[0;36mFFLinear.update\u001b[1;34m(self, pos_x, neg_x)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\n\u001b[0;32m     33\u001b[0m         torch\u001b[38;5;241m.\u001b[39mcat([\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     )\n\u001b[0;32m     38\u001b[0m )\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "class FFLinear(nn.Linear):\n",
    "    __constants__ = ('in_features', 'out_features')\n",
    "    in_features: int\n",
    "    out_features: int\n",
    "    weight: Tensor\n",
    "        \n",
    "    def __init__(self, in_feature: int, out_features: int, bias: bool=True, device=None, dtype=None) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super(FFLinear, self).__init__(in_feature, out_features, bias, **factory_kwargs)\n",
    "        \n",
    "        self.activation = nn.ReLU()\n",
    "        self.optim = torch.optim.SGD(self.parameters(), lr=0.01)\n",
    "        self.threshold = 2.0\n",
    "        \n",
    "    def forward(self, input) -> Tensor:\n",
    "        out = self.__layerNorm(input)\n",
    "        out = F.linear(out, self.weight, self.bias)\n",
    "        return self.activation(out)\n",
    "    \n",
    "    def update(self, pos_x, neg_x) -> Tensor:\n",
    "        pos_out = self.forward(pos_x).pow(exponent=2).mean(dim=1) #shape: (Batch, )\n",
    "        neg_out = self.forward(neg_x).pow(exponent=2).mean(dim=1) #shape: (Batch, )\n",
    "        \n",
    "        print('=' * 50)\n",
    "        print(pos_out)\n",
    "        print(neg_out)\n",
    "        print('=' * 50)\n",
    "        print(-pos_out + self.threshold)\n",
    "        print(neg_out - self.threshold)\n",
    "        print('=' * 50)\n",
    "        print(\n",
    "            1. + torch.exp(\n",
    "                torch.cat([\n",
    "                    -pos_out + self.threshold,\n",
    "                    neg_out - self.threshold\n",
    "                ])\n",
    "            )\n",
    "        )\n",
    "        raise\n",
    "    \n",
    "    def __layerNorm(self, input: Tensor, eps: float=1e-4) -> Tensor:\n",
    "        '''\n",
    "        + 참고 repository의 정규화 코드\n",
    "        input / (input.norm(p=2, dim=1, keepdim=True) + 1e-4)\n",
    "        \n",
    "        ## https://github.com/mohammadpz/pytorch_forward_forward/blob/main/main.py\n",
    "        '''\n",
    "        \n",
    "        mean_ = input.mean(dim=1, keepdim=True)\n",
    "        var_ = input.var(dim=1, keepdim=True, unbiased=False) #unbiased True=(N-1), False=N\n",
    "        return (input - mean_) / torch.sqrt(var_ + eps)\n",
    "    \n",
    "    \n",
    "    \n",
    "pos_x = torch.randn(2, 4)\n",
    "neg_x = torch.randn(2, 4)\n",
    "\n",
    "layer = FFLinear(4, 2)\n",
    "\n",
    "print(pos_x)\n",
    "print(neg_x)\n",
    "layer.update(pos_x, neg_x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
